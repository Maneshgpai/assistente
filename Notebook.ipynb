{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJh-O6yDz2kp",
        "outputId": "ad6c2798-8b7f-44b9-a092-ef3e4b19785a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gvrvykhvzqpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fcf36b4-893d-433c-cd02-f39a33db275c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting loguru\n",
            "  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-option-menu\n",
            "  Downloading streamlit_option_menu-0.3.6-py3-none-any.whl (799 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m799.2/799.2 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting streamlit-authenticator\n",
            "  Downloading streamlit-authenticator-0.2.3.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.1)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.37-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.0/190.0 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: PyJWT>=2.3.0 in /usr/lib/python3/dist-packages (from streamlit-authenticator) (2.3.0)\n",
            "Collecting bcrypt>=3.1.7 (from streamlit-authenticator)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from streamlit-authenticator) (6.0.1)\n",
            "Collecting extra-streamlit-components>=0.1.60 (from streamlit-authenticator)\n",
            "  Downloading extra_streamlit_components-0.1.60-py3-none-any.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Building wheels for collected packages: streamlit-authenticator\n",
            "  Building wheel for streamlit-authenticator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for streamlit-authenticator: filename=streamlit_authenticator-0.2.3-py3-none-any.whl size=10966 sha256=3fad7fabc688edb82e05a776e317206943ac75142f1312c50da0d87c504a53b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/eb/54/009e28abdb72f6bab333aff4549375b8c89185ea1d6e034109\n",
            "Successfully built streamlit-authenticator\n",
            "Installing collected packages: watchdog, validators, smmap, python-dotenv, PyPDF2, loguru, bcrypt, tiktoken, pydeck, gitdb, openai, gitpython, streamlit, streamlit-option-menu, extra-streamlit-components, streamlit-authenticator\n",
            "Successfully installed PyPDF2-3.0.1 bcrypt-4.0.1 extra-streamlit-components-0.1.60 gitdb-4.0.10 gitpython-3.1.37 loguru-0.7.2 openai-0.28.1 pydeck-0.8.1b0 python-dotenv-1.0.0 smmap-5.0.1 streamlit-1.27.2 streamlit-authenticator-0.2.3 streamlit-option-menu-0.3.6 tiktoken-0.5.1 validators-0.22.0 watchdog-3.0.0\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 2.18s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "cp: cannot stat '/content/drive/MyDrive/Colab Notebooks/.env': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/Colab Notebooks/config_assistente.yaml': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit openai PyPDF2 python-dotenv loguru streamlit-option-menu streamlit-authenticator tiktoken\n",
        "!npm install localtunnel\n",
        "# !mkdir pages\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/.env /content\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/config_assistente.yaml /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WECdDxMkzs8g",
        "outputId": "7edf8fa4-2dff-4e2f-b259-c24027d43d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.231.34.214\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.056s\n",
            "your url is: https://seven-pants-chew.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run main.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3WgIfxDzuYx"
      },
      "outputs": [],
      "source": [
        "# import streamlit_authenticator as stauth\n",
        "# print(stauth.Hasher(['Beta@123']).generate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCsUDfX6zk6O",
        "outputId": "29e17d14-9c08-4089-b254-1953430ed191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "from dotenv import load_dotenv\n",
        "from loguru import logger\n",
        "from streamlit_option_menu import option_menu\n",
        "import streamlit_authenticator as stauth\n",
        "import yaml\n",
        "from yaml.loader import SafeLoader\n",
        "import PyPDF2\n",
        "import io\n",
        "import sys\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import json\n",
        "import traceback\n",
        "import tiktoken\n",
        "# import datetime\n",
        "# import pytz\n",
        "import os\n",
        "# import zipfile\n",
        "\n",
        "# hashed_passwords = stauth.Hasher(['your_pwd_here']).generate()\n",
        "st.set_page_config(page_title='Assistente', page_icon = \"🇧🇷\", layout = 'wide', initial_sidebar_state = 'collapsed')\n",
        "with open('config_assistente.yaml') as file:\n",
        "    config = yaml.load(file, Loader=SafeLoader)\n",
        "authenticator = stauth.Authenticate(\n",
        "    config['credentials'],\n",
        "    config['cookie']['name'],\n",
        "    config['cookie']['key'],\n",
        "    config['cookie']['expiry_days'],\n",
        "    config['preauthorized']\n",
        ")\n",
        "\n",
        "def hideStreamlitHeader():\n",
        "    hide_st_style = \"\"\"\n",
        "            <style>\n",
        "            #MainMenu {visibility: hidden;}\n",
        "            footer {visibility: hidden;}\n",
        "            header {visibility: hidden;}\n",
        "            #root > div:nth-child(1) > div > div > div > div > section > div {padding-top: 0rem;}\n",
        "            </style>\n",
        "            \"\"\"\n",
        "    st.markdown(hide_st_style, unsafe_allow_html=True)\n",
        "hideStreamlitHeader()\n",
        "\n",
        "col1, col2, col3 = st.columns(3)\n",
        "with col1:\n",
        "  st.write('')\n",
        "with col2:\n",
        "  name, authentication_status, username = authenticator.login('Login', 'main')\n",
        "with col3:\n",
        "  st.write('')\n",
        "\n",
        "####################################### SKIP LOGIN #########################################\n",
        "st.session_state[\"authentication_status\"]=True\n",
        "####################################### SKIP LOGIN #########################################\n",
        "\n",
        "if st.session_state[\"authentication_status\"]:\n",
        "################################################################################\n",
        "\n",
        "  ### Define session vars ###\n",
        "  if \"vLang\" not in st.session_state:\n",
        "    st.session_state[\"vLang\"]=False\n",
        "  if \"file_uploader_key\" not in st.session_state:\n",
        "    st.session_state[\"file_uploader_key\"] = 0\n",
        "  if \"vFileData\" not in st.session_state:\n",
        "    st.session_state[\"vFileData\"]=\"\"\n",
        "  if \"vSmry\" not in st.session_state:\n",
        "    st.session_state[\"vSmry\"]=\"\"\n",
        "  if \"vArbResp\" not in st.session_state:\n",
        "    st.session_state[\"vArbResp\"]=\"\"\n",
        "  if \"vIsArbSubmit\" not in st.session_state:\n",
        "    st.session_state[\"vIsArbSubmit\"]=False\n",
        "  if \"vPrcedncResp\" not in st.session_state:\n",
        "    st.session_state[\"vPrcedncResp\"] = \"\"\n",
        "  if \"vflNm\" not in st.session_state:\n",
        "    st.session_state[\"vflNm\"] = \"\"\n",
        "\n",
        "  col1, col2 = st.columns([0.88, 0.12])\n",
        "  with col1:\n",
        "    st.write(' ')\n",
        "  with col2:\n",
        "    st.session_state[\"vLang\"] = st.toggle(\"English\", value=True)\n",
        "\n",
        "  ### Welcome and Logout buttons ###\n",
        "  # col1, col2 = st.columns([0.9, 0.1])\n",
        "  # with col1:\n",
        "  #   st.caption(f'Welcome **{st.session_state[\"name\"]}**')\n",
        "  # with col2:\n",
        "  #   authenticator.logout('Logout', 'main', key='unique_key')\n",
        "\n",
        "  ### Define global vars ###\n",
        "  if st.session_state[\"vLang\"]:\n",
        "    vPgHome = 'Home'\n",
        "    vPgSetting = 'Setting'\n",
        "    vHomeTitle = '**Welcome to A.I based Legal assistant**'\n",
        "    vHomeHeader = 'To summarize case files, identify the right court, clarify doubts on legal matters, search for old case records\\\n",
        "    and much more.\\\n",
        "    \\n\\\n",
        "    More features coming soon. Stay tuned!'\n",
        "    vSettingPgHeader='Work in progress...'\n",
        "    vFileUpldrLabel='Upload case file'\n",
        "    vSubmitHomeFileUpldLabel=\"Summarize\"\n",
        "    vCheckButtonLabel=\"Submit\"\n",
        "    css='''\n",
        "      <style>\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::before {content:\"Drag and drop file here\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div span{display:none;}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::after {color:grey; font-size: .8em; content:\"Limit 20MB per file • PDF\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div small{display:none;}\n",
        "      </style>\n",
        "      '''\n",
        "    st.markdown(css, unsafe_allow_html=True)\n",
        "\n",
        "    vResponseTitle='Summarising '\n",
        "    vWarningNoFileUpld = 'Warning: Please upload case file to proceed'\n",
        "    vSmryDwnldButtonMsg = 'Download case summary :arrow_down:'\n",
        "    vArbDwnldButtonMsg = 'Download arbitration summary :arrow_down:'\n",
        "    vPrecDwnldButtonMsg = 'Download precedence summary:arrow_down:'\n",
        "    vGenericDwnldButtonMsg = 'Download :arrow_down:'\n",
        "    vSmryFileNm='summary'\n",
        "    vArbRespFileNm='arbitration'\n",
        "    vPrcedncRespFileNm='precedence'\n",
        "    vIsArbitrationQue = 'Step 2. Would you like to check if this case qualifies for private arbitration?'\n",
        "    vOptionNo='No'\n",
        "    vOptionYes='Yes'\n",
        "    vIsPrecedenceQue='Step 3. Would you like to check for precedence?'\n",
        "    vCaseSummaryQue='Step 1. Please upload the case file to begin'\n",
        "    vDisclaimerArb='Views expressed by the system are generated by an artificial intelligence. It is important to consult with a qualified attorney to further evaluate the \\\n",
        "      specific circumstances of the case and ensure compliance with the latest legal structure in Brazil.'\n",
        "    vDisclaimerPrec='As an A.I, I have limited access to prior legal files. We are working in the background to bring this feature soon.'\n",
        "  else:\n",
        "    vPgHome = 'lar'\n",
        "    vPgSetting = 'contexto'\n",
        "    vHomeTitle = '**Bem-vindo ao seu próprio assistente jurídico de A.I**'\n",
        "    vHomeHeader = 'Por toda a sua assistência jurídica, como resumir arquivos de casos, identificar o judiciário correto a ser instaurado e muito mais. \\\n",
        "      \\n\\\n",
        "      Muitos mais recursos estão chegando. Fique atento!'\n",
        "    vSettingPgHeader='trabalho em progresso...'\n",
        "    vFileUpldrLabel='Carregar arquivo do caso'\n",
        "    vSubmitHomeFileUpldLabel=\"Resumir\"\n",
        "    vCheckButtonLabel=\"Enviar\"\n",
        "    css='''\n",
        "      <style>\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::before {content:\"Arraste e solte o arquivo aqui\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div span{display:none;}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::after {color:grey; font-size: .8em; content:\"Limite de 20MB por arquivo • PDF\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div small{display:none;}\n",
        "      </style>\n",
        "      '''\n",
        "    st.markdown(css, unsafe_allow_html=True)\n",
        "    vResponseTitle='Resumindo '\n",
        "    vWarningNoFileUpld = 'Aviso: faça upload do arquivo do caso para prosseguir'\n",
        "    vSmryDwnldButtonMsg = 'Baixar resumo do caso :arrow_down:'\n",
        "    vArbDwnldButtonMsg = 'Baixe o resumo da arbitragem :arrow_down:'\n",
        "    vPrecDwnldButtonMsg = 'Baixar resumo de precedência :arrow_down:'\n",
        "    vGenericDwnldButtonMsg = 'Baixar :arrow_down:'\n",
        "    vSmryFileNm='resumido'\n",
        "    vArbRespFileNm='arbitragem'\n",
        "    vPrcedncRespFileNm='precedência'\n",
        "    vIsArbitrationQue = 'Etapa 2. Gostaria de verificar se este caso se qualifica para arbitragem privada?'\n",
        "    vOptionNo='Não'\n",
        "    vOptionYes='Sim'\n",
        "    vIsPrecedenceQue='Etapa 3. Gostaria de verificar a precedência?'\n",
        "    vDisclaimerArb='As opiniões expressas pelo sistema são geradas por uma inteligência artificial. É importante consultar um advogado qualificado para avaliar melhor o \\\n",
        "      circunstâncias específicas do caso e garantir o cumprimento da mais recente estrutura jurídica do Brasil.'\n",
        "    vDisclaimerPrec='Como A.I, tenho acesso limitado a arquivos jurídicos antigos. Mas estamos trabalhando em segundo plano para trazer esse recurso em breve.'\n",
        "    vCaseSummaryQue='Etapa 1. Faça upload do arquivo do caso para começar'\n",
        "\n",
        "  load_dotenv()\n",
        "  openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  input_files = []\n",
        "  vUpldMultipleFiles = False\n",
        "  vResponse = \"\"\n",
        "  flName = \"\"\n",
        "  vPg = vPgHome\n",
        "  # llm_model = \"gpt-3.5-turbo\" #For Dev\n",
        "  llm_model = \"gpt-4\" #For Prod\n",
        "\n",
        "  ### Initiate logging ###\n",
        "  logger_format = (\n",
        "      \"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \"\n",
        "      \"<level>{level: <8}</level> | \"\n",
        "      \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | \"\n",
        "      +username+\" | \"\n",
        "      \"{extra[ip]} {extra[user]} - <level>{message}</level>\"\n",
        "  )\n",
        "  logger.configure(extra={\"ip\": \"\", \"user\": \"\"})  # Default values\n",
        "  logger.remove()\n",
        "  logger.add(username+\"_{time:YYYY-MM-DD!UTC}.log\", format=logger_format, rotation=\"10 MB\", compression=\"zip\")\n",
        "  logger.info(\"*********** Started Assistente ***********\")\n",
        "\n",
        "  ### Start funcs definitions ###\n",
        "\n",
        "  encoding = tiktoken.encoding_for_model(llm_model)\n",
        "  def num_tokens_from_response(response_text):\n",
        "    num_tokens = len(encoding.encode(response_text))\n",
        "    return num_tokens\n",
        "\n",
        "  def num_tokens_from_messages(messages):\n",
        "    tokens_per_message = 3\n",
        "    tokens_per_name = 1\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "      num_tokens += tokens_per_message\n",
        "      for key, value in message.items():\n",
        "        num_tokens += len(encoding.encode(value))\n",
        "        if key == \"name\":\n",
        "          num_tokens += tokens_per_name\n",
        "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
        "    return num_tokens\n",
        "\n",
        "  def getOpenaiApiCost(llm_name,completion_tokens,prompt_tokens):\n",
        "    if llm_name == \"gpt-3.5-turbo\":\n",
        "      ###\t4K context: Input/Prompt tokens @ $0.0015/1K tokens, Output/Response tokens @ $0.002/1K tokens\n",
        "      ip_cost = (prompt_tokens/1000) * 0.0015\n",
        "      op_cost = (completion_tokens/1000) * 0.002\n",
        "\n",
        "    elif llm_name == \"gpt-3.5-turbo-16k\":\n",
        "      ###\t16K context: Input/Prompt tokens @ $0.003/1K tokens, Output/Response tokens @ $0.004/1K tokens\n",
        "      ip_cost = (prompt_tokens/1000) * 0.003\n",
        "      op_cost = (completion_tokens/1000) * 0.004\n",
        "\n",
        "    elif llm_name == \"gpt-4\":\n",
        "      ###\t8K context: Input/Prompt tokens @ $0.03/1K tokens, Output/Response tokens @ $0.06/1K tokens\n",
        "      ip_cost = (prompt_tokens/1000) * 0.03\n",
        "      op_cost = (completion_tokens/1000) * 0.06\n",
        "\n",
        "    tot_cost = round((op_cost + ip_cost),4)\n",
        "    return (tot_cost)\n",
        "\n",
        "  def getFileData(rawFileData):\n",
        "    file_extension = pathlib.Path(rawFileData.name).suffix\n",
        "    logger.info(\"file_extension:{var}\",var=file_extension)\n",
        "    if file_extension.upper()=='.TXT':\n",
        "      file_data = rawFileData.getvalue().decode('utf-8')\n",
        "    elif file_extension.upper()=='.PDF':\n",
        "      file_pages = []\n",
        "      p = io.BytesIO(rawFileData.getvalue());\n",
        "      pdf = PyPDF2.PdfReader(p)\n",
        "      for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        file_pages.append(text)\n",
        "        file_data = ''\n",
        "        for k in range(len(file_pages)):\n",
        "          file_data = file_data + file_pages[k]\n",
        "    logger.info(\"Data from file:{var}\",var=file_data)\n",
        "    return file_data\n",
        "\n",
        "  def getAiMessages(prompt):\n",
        "     message = [{\"role\": \"system\", \"content\": \"Assistant is an highly experienced lawyer from Brazil,\\\n",
        "     who knows both portugese and english language and is an expert in all matters related to legal, judicial,\\\n",
        "     and laws\"},{\"role\": \"user\", \"content\": prompt}]\n",
        "     return message\n",
        "\n",
        "  def getAiResponse(message, isStreaming, prompt, llm_model, temperature):\n",
        "    result = \"\"\n",
        "    collected_messages = []\n",
        "    report1 = []\n",
        "    res_box1 = st.empty()\n",
        "    response = openai.ChatCompletion.create(model=llm_model, messages=message, temperature=temperature, stream=isStreaming,)\n",
        "    for chunk in response:\n",
        "      chunk_message = chunk['choices'][0]['delta']\n",
        "      collected_messages.append(chunk_message)\n",
        "      if \"content\" in chunk_message:\n",
        "        report1.append(chunk_message['content'])\n",
        "        result = \"\".join(report1)\n",
        "        res_box1.success(f'*{result}*')\n",
        "    vResponse = [''.join([m.get('content', '') for m in collected_messages])]\n",
        "    return vResponse\n",
        "\n",
        "  def getSmryPrompt(data):\n",
        "    if (st.session_state[\"vLang\"]):\n",
        "      vLang = 'English'\n",
        "    else:\n",
        "      vLang = 'Portueguese'\n",
        "    prompt = f\"\"\"Your task is to summarize in atleast 300 words, the legal document provided between three backticks in {vLang} language.\n",
        "    It is VERY IMPORTANT that you include only the summarised text and nothing else, not a title, post script or any other text.\n",
        "    You will summarise the legal document in the format and language of a very efficient and experienced advocate.\n",
        "\n",
        "    It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    After fetching the response, you will review the response to check if you have followed the critera provided between\\\n",
        "     triple commas as delimiters\n",
        "    ,,,You will review the summary for any important legal points which is missed.\n",
        "    You should review as per the latest legal structure of Brazil.\n",
        "    You will include all personal information or PII data related to any person, all dates, names of places, companies etc.\n",
        "    Include only the summarized response. Do not include any title or post script or anyother text which is not related \\\n",
        "    to the legal document provided between three backticks\\\n",
        "    The response should be in {vLang} language.\n",
        "    ,,,\n",
        "    ```{data}```\n",
        "    \"\"\"\n",
        "\n",
        "    # prompt = f\"\"\"Your task is to summarize in less than 10 words, the legal document provided between three backticks in {vLang} language.\n",
        "    # It is VERY IMPORTANT that you include only the summarised text and nothing else, not a title, post script or any other text.\n",
        "    # You will summarise the legal document in the format and language of a very efficient and experienced advocate.\n",
        "\n",
        "    # It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    # After fetching the response, you will review the response to check if you have followed the critera provided between\\\n",
        "    #  triple commas as delimiters\n",
        "    # ,,,You will review the summary for any important legal points which is missed.\n",
        "    # You should review as per the latest legal structure of Brazil.\n",
        "    # You will include all personal information or PII data related to any person, all dates, names of places, companies etc.\n",
        "    # Include only the summarized response. Do not include any title or post script or anyother text which is not related \\\n",
        "    # to the legal document provided between three backticks\\\n",
        "    # The response should be in {vLang} language.\n",
        "    # ,,,\n",
        "    # ```{data}```\n",
        "    # \"\"\"\n",
        "    logger.info(prompt)\n",
        "    return prompt\n",
        "\n",
        "  def getPromptIsArbitration(data):\n",
        "    if (st.session_state[\"vLang\"]):\n",
        "      vLang = 'English'\n",
        "    else:\n",
        "      vLang = 'Portuguese'\n",
        "\n",
        "    prompt = f\"\"\"Your task is to check if the case summary provided between three backticks, \\\n",
        "    qualify for private arbitrage in brazil.\\\n",
        "    You will arrive at the decision by considering the Brazil Arbitration Act (Law No. 9.307/1996).\n",
        "    It is VERY IMPORTANT that you consider the guidelines provided between three tilde symbols.\n",
        "    ~~~\n",
        "    You will assume that both parties have consented for entering into an written arbitration agreement.\n",
        "    Carefully analyze the case summary provided the between three backticks to see if this case qualifies to be tried under \\\n",
        "    private arbitration in Brazil under Brazil Arbitration Act (Law No. 9.307/1996)?\n",
        "    You will use the tone and language of an experienced advocate from Brazil.\n",
        "    You will not paraphrase or include the case summary in your response.\n",
        "    The decision should be based only on Brazil Arbitration Act (Law No. 9.307/1996).~~~\n",
        "\n",
        "    It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    After fetching the response, you will STRICTLY ensure the response follows the guidelines mentioned between three plus signs.\\\n",
        "    +++Your response should only the clarification whether the case qualifies for private arbitration in Brazil. \\\n",
        "    It should also have the why or the reason for considering this under private arbitration.\n",
        "    You should remove the intial paraphrasing of summary from the response.\n",
        "    The language of response should be in {vLang}.\n",
        "    +++\n",
        "\n",
        "    ```{data}```\n",
        "    \"\"\"\n",
        "\n",
        "    # prompt = f\"\"\"Your task is to check if the case summary provided between three backticks, \\\n",
        "    # qualify for private arbitrage in brazil.\\\n",
        "    # You will arrive at the decision by considering the Brazil Arbitration Act (Law No. 9.307/1996).\n",
        "    # It is VERY IMPORTANT that you consider the guidelines provided between three tilde symbols.\n",
        "    # ~~~\n",
        "    # You will assume that both parties have consented for entering into an written arbitration agreement.\n",
        "    # Carefully analyze the case summary provided the between three backticks to see if this case qualifies to be tried under \\\n",
        "    # private arbitration in Brazil under Brazil Arbitration Act (Law No. 9.307/1996)?\n",
        "    # You will use the tone and language of an experienced advocate from Brazil.\n",
        "    # You will not paraphrase or include the case summary in your response.\n",
        "    # The decision should be based only on Brazil Arbitration Act (Law No. 9.307/1996).~~~\n",
        "\n",
        "    # It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language in LESS THAN 10 WORDS.\n",
        "\n",
        "    # After fetching the response, you will STRICTLY ensure the response follows the guidelines mentioned between three plus signs.\\\n",
        "    # +++Your response should only the clarification whether the case qualifies for private arbitration in Brazil. \\\n",
        "    # It should also have the why or the reason for considering this under private arbitration.\n",
        "    # You should remove the intial paraphrasing of summary from the response.\n",
        "    # The language of response should be in {vLang}.\n",
        "    # +++\n",
        "\n",
        "    # ```{data}```\n",
        "    # \"\"\"\n",
        "\n",
        "    logger.info(prompt)\n",
        "    return prompt\n",
        "\n",
        "  def getPromptIsPrecedence(data, vDisclaimerPrec):\n",
        "    if (st.session_state[\"vLang\"]):\n",
        "      vLang = 'English'\n",
        "    else:\n",
        "      vLang = 'Portuguese'\n",
        "\n",
        "    prompt = f\"\"\"Your task is to check if the case summary provided between three backticks, \\\n",
        "    has any precedence in in brazil. You will arrive at the decision by following the instructions given between three Tilde symbols.\n",
        "    ~~~ Carefully analyze the case summary provided the between three backticks.\n",
        "    Compare it against the cases from Brazil legal system, to only what you have access to.\n",
        "    If you do not have any access, do not generate hallucinations or imaginary cases.\n",
        "    Check the precedence of the similar case in this 10 years of Brazil's legal system.~~~\n",
        "\n",
        "    It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    After fetching the response, you will STRICTLY follow the guidelines given between three Hash symbols.\\\n",
        "    ### You will rewrite the response in the tone, format and language of a very efficient and highly experienced advocate from Brazil.\\\n",
        "    You will check TWICE whether the precedence cited are imaginary or hallucinations. If they are either, you will reject them.\n",
        "    You will check TWICE whether the Citation URLs are working or not. If they are not working, you will not include any imaginary or placeholder URLs.\n",
        "    You will not include any summary of the case provided between three backticks. You will only include details of the precedence\n",
        "\n",
        "    You will give your response in only STRICTLY IN JSON format and in {vLang} language. You will not provide any other text beyond this JSON data in {vLang} language.\n",
        "    [Case_file=input details of precedence cases,Verdict_Date=Input date of precedence cases here, Judgement=Input the verdict give and against whom in the preceednce case, Citation=Input the working URL to the precedence case]\n",
        "    ,[Case_file=input details of precedence cases,Verdict_Date=Input date of precedence cases here, Judgement=Input the verdict give and against whom in the preceednce case, Citation=Input the working URL to the precedence case]\n",
        "    If you do not have any precedence case, you will respond with empty JSON.\n",
        "\n",
        "    Before generating the response you will again check whether the response follows the guidelines given between three Hash symbols.\n",
        "\n",
        "    You will give your response in only STRICTLY IN JSON format. You will not provide any other text beyond this JSON data.\n",
        "    If you do not have any precedence case, you will respond with JSON in below format.\n",
        "    [{vDisclaimerPrec}]\n",
        "\n",
        "    ```{data}```\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(prompt)\n",
        "    return prompt\n",
        "\n",
        "  def renderHomePgHeader():\n",
        "    st.subheader(vHomeTitle)\n",
        "    st.info(vHomeHeader)\n",
        "\n",
        "  def renderSettingPg():\n",
        "    st.subheader(vSettingPgHeader)\n",
        "\n",
        "  # @logger.catch\n",
        "  # @st.cache_data(max_entries=3,ttl=3600,show_spinner=False)\n",
        "  # def summarizeFiles(data):\n",
        "  #   prompt = getSmryPrompt(data)\n",
        "  #   vResponse = getAiResponse(True,prompt,llm_model,0.3)\n",
        "  #   return vResponse[0]\n",
        "\n",
        "  def renderResponse(df):\n",
        "    st.divider()\n",
        "    st.dataframe(df, use_container_width=True)\n",
        "    st.divider()\n",
        "\n",
        "  def renderMenubar():\n",
        "    col1, col2 = st.columns([0.5, 0.5])\n",
        "    with col1:\n",
        "      vPg = option_menu(None, [vPgHome, vPgSetting],\n",
        "      icons=['house', 'gear'],\n",
        "      menu_icon=\"cast\", default_index=0, orientation=\"horizontal\")\n",
        "    with col2:\n",
        "      st.write(' ')\n",
        "    return vPg\n",
        "\n",
        "  def dwnldSmryResp(data):\n",
        "    return data\n",
        "\n",
        "  def dwnldArbResp(data):\n",
        "    return data\n",
        "\n",
        "  def dwnldPrcedncResp(data):\n",
        "    if str(data[0]) == '{}':\n",
        "      return vDisclaimerPrec\n",
        "    else:\n",
        "      return data\n",
        "\n",
        "################################################################################\n",
        "\n",
        "  # vPg = renderMenubar()\n",
        "  if vPg == vPgHome:\n",
        "    renderHomePgHeader()\n",
        "    col1, col2, col3 = st.columns([0.15,0.7,0.15])\n",
        "    with col1:\n",
        "      st.write(\" \")\n",
        "    with col2:\n",
        "      tab1, tab2 = st.tabs([\" \",\" \"])\n",
        "      with tab1:\n",
        "        with st.form(\"smry\", clear_on_submit=True):\n",
        "          col4, col5 = st.columns([0.85,0.15])\n",
        "          with col4:\n",
        "            st.subheader(vCaseSummaryQue)\n",
        "          with col5:\n",
        "            vSubmitHomeFileUpld = st.form_submit_button(vSubmitHomeFileUpldLabel, type=\"primary\")\n",
        "          input_files = st.file_uploader(\"\", type=['pdf'], accept_multiple_files=vUpldMultipleFiles,key=st.session_state[\"file_uploader_key\"],label_visibility=\"visible\")\n",
        "          if vSubmitHomeFileUpld and not(input_files):\n",
        "            st.warning(vWarningNoFileUpld)\n",
        "            st.session_state[\"vSmry\"] = \"\"\n",
        "          if vSubmitHomeFileUpld and not(not(input_files)):\n",
        "            fl_ext = pathlib.Path(input_files.name).suffix\n",
        "            st.session_state[\"vflNm\"] = input_files.name.replace(fl_ext,'')\n",
        "\n",
        "            with st.spinner('Processing...'):\n",
        "              file_data = getFileData(input_files).strip()\n",
        "              st.session_state[\"vFileData\"]=file_data\n",
        "              prompt = getSmryPrompt(file_data)\n",
        "              message = getAiMessages(prompt)\n",
        "              prompt_tokens = num_tokens_from_messages(message)\n",
        "\n",
        "            tokenSzExceed = False\n",
        "            if prompt_tokens < 4000:\n",
        "              smry_llm=\"gpt-3.5-turbo\"\n",
        "            elif prompt_tokens > 4000 and prompt_tokens < 8000:\n",
        "              smry_llm=\"gpt-4\"\n",
        "            elif prompt_tokens > 8000 and prompt_tokens < 16000:\n",
        "              smry_llm=\"gpt-3.5-turbo-16k\"\n",
        "            else:\n",
        "              tokenSzExceed = True\n",
        "\n",
        "            if not(tokenSzExceed):\n",
        "              vResponse = getAiResponse(message, True, prompt, smry_llm, 0)\n",
        "              st.session_state[\"vSmry\"] = vResponse[0]\n",
        "              completion_tokens = num_tokens_from_response(st.session_state[\"vSmry\"])\n",
        "            else:\n",
        "              st.error(\"prompt_tokens:\"+str(prompt_tokens))\n",
        "              st.error('Currently system can handle only small case files.\\\n",
        "                \\n\\\n",
        "                We are working in the background to increase this limit!')\n",
        "\n",
        "        col1,col2 = st.columns([0.7,0.3])\n",
        "        with col1:\n",
        "          st.write('')\n",
        "        with col2:\n",
        "          if st.session_state[\"vSmry\"] != '':\n",
        "            st.write()\n",
        "            st.download_button(vSmryDwnldButtonMsg, (st.session_state[\"vSmry\"]), file_name=st.session_state[\"vflNm\"]+'_'+vSmryFileNm+'.txt', type=\"secondary\", key='SmryDwnld', use_container_width=True)\n",
        "\n",
        "        if st.session_state[\"vSmry\"] != '':\n",
        "          st.write(\"--------------------------------------------------------------\")\n",
        "          with st.form(\"arbitr\", clear_on_submit=True):\n",
        "            col1,col2 = st.columns([0.85,0.15])\n",
        "            with col1:\n",
        "              st.write(vIsArbitrationQue)\n",
        "            with col2:\n",
        "              vIsArbitrationSubmit = st.form_submit_button(vCheckButtonLabel, type=\"primary\")\n",
        "            if vIsArbitrationSubmit:\n",
        "              st.session_state[\"vIsArbSubmit\"] = True\n",
        "              with st.expander('', expanded=True):\n",
        "                prompt = getPromptIsArbitration(st.session_state[\"vSmry\"])\n",
        "                message = getAiMessages(prompt)\n",
        "                vResp = getAiResponse(message,True,prompt,llm_model,0)\n",
        "                st.session_state[\"vArbResp\"] = vResp[0]\n",
        "\n",
        "        if st.session_state[\"vArbResp\"]:\n",
        "          col1,col2 = st.columns([0.65,0.35])\n",
        "          with col1:\n",
        "            st.write('')\n",
        "          with col2:\n",
        "            st.download_button(vArbDwnldButtonMsg, dwnldArbResp(st.session_state[\"vArbResp\"]), file_name=st.session_state[\"vflNm\"]+'_'+vArbRespFileNm+vSmryFileNm+'.txt', type=\"secondary\", key='IsArbitrationDwnld',use_container_width=True)\n",
        "          st.caption(f':Gray[{vDisclaimerArb}]')\n",
        "          st.session_state[\"vIsArbSubmit\"] = False\n",
        "\n",
        "        if st.session_state[\"vFileData\"] != '':\n",
        "          st.write(\"--------------------------------------------------------------\")\n",
        "          with st.form(\"prece\", clear_on_submit=True):\n",
        "            col1,col2 = st.columns([0.85,0.15])\n",
        "            with col1:\n",
        "              st.write(vIsPrecedenceQue)\n",
        "            with col2:\n",
        "              vIsPrecedenceSubmit = st.form_submit_button(vCheckButtonLabel, type=\"primary\")\n",
        "            if vIsPrecedenceSubmit and st.session_state[\"vFileData\"] != '':\n",
        "              with st.expander('', expanded=True):\n",
        "                prompt = getPromptIsPrecedence(st.session_state[\"vSmry\"], vDisclaimerPrec)\n",
        "                message = getAiMessages(prompt)\n",
        "                # vResp = getAiResponse(message,True,prompt,llm_model,0)\n",
        "                # st.session_state[\"vPrcedncResp\"] = vResp[0]\n",
        "                st.session_state[\"vPrcedncResp\"] = vDisclaimerPrec\n",
        "                st.success(vDisclaimerPrec)\n",
        "\n",
        "        if st.session_state[\"vPrcedncResp\"] != '':\n",
        "          col1,col2 = st.columns([0.64,0.36])\n",
        "          with col1:\n",
        "            st.write('')\n",
        "          with col2:\n",
        "            st.download_button(vPrecDwnldButtonMsg, dwnldPrcedncResp(st.session_state[\"vPrcedncResp\"]), file_name=st.session_state[\"vflNm\"]+'_'+vPrcedncRespFileNm+vSmryFileNm+'.txt', type=\"secondary\", key='IsPrcedncDwnld',use_container_width=True)\n",
        "          # st.caption(f':Gray[{vDisclaimerPrec}]')\n",
        "      with tab2:\n",
        "        st.write('')\n",
        "\n",
        "    with col3:\n",
        "      st.write(\" \")\n",
        "\n",
        "elif st.session_state[\"authentication_status\"] is False:\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    st.write('')\n",
        "  with col2:\n",
        "    st.error('Username/password is incorrect')\n",
        "  with col3:\n",
        "    st.write('')\n",
        "elif st.session_state[\"authentication_status\"] is None:\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    st.write('')\n",
        "  with col2:\n",
        "    st.warning('Please enter your username and password')\n",
        "  with col3:\n",
        "    st.write('')\n",
        "else:\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    st.write('')\n",
        "  with col2:\n",
        "    st.error('Contact admin @ maneshgpai@gmail.com')\n",
        "  with col3:\n",
        "    st.write('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq7VLkrECcWE"
      },
      "source": [
        "#Code to generate unique pass key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKGiW6EZCbqw"
      },
      "outputs": [],
      "source": [
        "# pip install cryptography\n",
        "from cryptography.fernet import Fernet\n",
        "# Put this somewhere safe!\n",
        "key = Fernet.generate_key()\n",
        "print(key)\n",
        "f = Fernet(key)\n",
        "token = f.encrypt(b\"medcodecookie\")\n",
        "print(token)\n",
        "\n",
        "### To decrypt the key:\n",
        "# f.decrypt(token)\n",
        "\n",
        "### Keys generated for stauth YAML:\n",
        "# Crypto fernet key: Rf7N6vpG_G_2MITkoJ9KbN4HRfNoWpyBdrYwIiU_9vc=\n",
        "# Cookie key for stauth YAML file: gAAAAABlJVNLvN6Yi0KH-xmBGP3lJYw7YDWdPr-dHn4hC0IR2foOai1GGTszI7MCcijAyecLKrk3GiJp_dTaQ47bsBqRN1k-vA==\n",
        "# Cookie Name for stauth YAML file: medcodecookie"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}