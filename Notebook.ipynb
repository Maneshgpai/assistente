{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maneshgpai/assistente/blob/main/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJh-O6yDz2kp",
        "outputId": "ad6c2798-8b7f-44b9-a092-ef3e4b19785a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvrvykhvzqpt"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit openai PyPDF2 python-dotenv loguru streamlit-option-menu streamlit-authenticator tiktoken\n",
        "!npm install localtunnel\n",
        "# !mkdir pages\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/.env /content\n",
        "!cp /content/drive/MyDrive/Colab\\ Notebooks/config_assistente.yaml /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WECdDxMkzs8g",
        "outputId": "7edf8fa4-2dff-4e2f-b259-c24027d43d75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.231.34.214\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.056s\n",
            "your url is: https://seven-pants-chew.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!streamlit run main.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3WgIfxDzuYx"
      },
      "outputs": [],
      "source": [
        "# import streamlit_authenticator as stauth\n",
        "# print(stauth.Hasher(['Beta@123']).generate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCsUDfX6zk6O",
        "outputId": "29e17d14-9c08-4089-b254-1953430ed191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "import openai\n",
        "import streamlit as st\n",
        "from dotenv import load_dotenv\n",
        "from loguru import logger\n",
        "from streamlit_option_menu import option_menu\n",
        "import streamlit_authenticator as stauth\n",
        "import yaml\n",
        "from yaml.loader import SafeLoader\n",
        "import PyPDF2\n",
        "import io\n",
        "import sys\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import json\n",
        "import traceback\n",
        "import tiktoken\n",
        "# import datetime\n",
        "# import pytz\n",
        "import os\n",
        "# import zipfile\n",
        "\n",
        "# hashed_passwords = stauth.Hasher(['your_pwd_here']).generate()\n",
        "st.set_page_config(page_title='Assistente', page_icon = \"ðŸ‡§ðŸ‡·\", layout = 'wide', initial_sidebar_state = 'collapsed')\n",
        "with open('config_assistente.yaml') as file:\n",
        "    config = yaml.load(file, Loader=SafeLoader)\n",
        "authenticator = stauth.Authenticate(\n",
        "    config['credentials'],\n",
        "    config['cookie']['name'],\n",
        "    config['cookie']['key'],\n",
        "    config['cookie']['expiry_days'],\n",
        "    config['preauthorized']\n",
        ")\n",
        "\n",
        "def hideStreamlitHeader():\n",
        "    hide_st_style = \"\"\"\n",
        "            <style>\n",
        "            #MainMenu {visibility: hidden;}\n",
        "            footer {visibility: hidden;}\n",
        "            header {visibility: hidden;}\n",
        "            #root > div:nth-child(1) > div > div > div > div > section > div {padding-top: 0rem;}\n",
        "            </style>\n",
        "            \"\"\"\n",
        "    st.markdown(hide_st_style, unsafe_allow_html=True)\n",
        "hideStreamlitHeader()\n",
        "\n",
        "col1, col2, col3 = st.columns(3)\n",
        "with col1:\n",
        "  st.write('')\n",
        "with col2:\n",
        "  name, authentication_status, username = authenticator.login('Login', 'main')\n",
        "with col3:\n",
        "  st.write('')\n",
        "\n",
        "####################################### SKIP LOGIN #########################################\n",
        "# st.session_state[\"authentication_status\"]=True\n",
        "####################################### SKIP LOGIN #########################################\n",
        "\n",
        "if st.session_state[\"authentication_status\"]:\n",
        "################################################################################\n",
        "\n",
        "  ### Define session vars ###\n",
        "  if \"vLang\" not in st.session_state:\n",
        "    st.session_state[\"vLang\"]=False\n",
        "  if \"file_uploader_key\" not in st.session_state:\n",
        "    st.session_state[\"file_uploader_key\"] = 0\n",
        "  if \"vFileData\" not in st.session_state:\n",
        "    st.session_state[\"vFileData\"]=\"\"\n",
        "  if \"vSmry\" not in st.session_state:\n",
        "    st.session_state[\"vSmry\"]=\"\"\n",
        "  if \"vArbResp\" not in st.session_state:\n",
        "    st.session_state[\"vArbResp\"]=\"\"\n",
        "  if \"vIsArbSubmit\" not in st.session_state:\n",
        "    st.session_state[\"vIsArbSubmit\"]=False\n",
        "  if \"vPrcedncResp\" not in st.session_state:\n",
        "    st.session_state[\"vPrcedncResp\"] = \"\"\n",
        "  if \"vflNm\" not in st.session_state:\n",
        "    st.session_state[\"vflNm\"] = \"\"\n",
        "\n",
        "  col1, col2 = st.columns([0.88, 0.12])\n",
        "  with col1:\n",
        "    st.write(' ')\n",
        "  with col2:\n",
        "    st.session_state[\"vLang\"] = st.toggle(\"English\", value=True)\n",
        "\n",
        "  ### Welcome and Logout buttons ###\n",
        "  col1, col2 = st.columns([0.9, 0.1])\n",
        "  with col1:\n",
        "    st.caption(f'Welcome **{st.session_state[\"name\"]}**')\n",
        "  with col2:\n",
        "    authenticator.logout('Logout', 'main', key='unique_key')\n",
        "\n",
        "  ### Define global vars ###\n",
        "  if st.session_state[\"vLang\"]:\n",
        "    vPgHome = 'Home'\n",
        "    vPgSetting = 'Setting'\n",
        "    vHomeTitle = '**Welcome to A.I based Legal assistant**'\n",
        "    vHomeHeader = 'To summarize case files, identify the right court, clarify doubts on legal matters, search for old case records\\\n",
        "    and much more.\\\n",
        "    \\n\\\n",
        "    More features coming soon. Stay tuned!'\n",
        "    vSettingPgHeader='Work in progress...'\n",
        "    vFileUpldrLabel='Upload case file'\n",
        "    vSubmitHomeFileUpldLabel=\"Summarize\"\n",
        "    vCheckButtonLabel=\"Submit\"\n",
        "    css='''\n",
        "      <style>\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::before {content:\"Drag and drop file here\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div span{display:none;}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::after {color:grey; font-size: .8em; content:\"Limit 20MB per file â€¢ PDF\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div small{display:none;}\n",
        "      </style>\n",
        "      '''\n",
        "    st.markdown(css, unsafe_allow_html=True)\n",
        "\n",
        "    vResponseTitle='Summarising '\n",
        "    vWarningNoFileUpld = 'Warning: Please upload case file to proceed'\n",
        "    vSmryDwnldButtonMsg = 'Download case summary :arrow_down:'\n",
        "    vArbDwnldButtonMsg = 'Download arbitration summary :arrow_down:'\n",
        "    vPrecDwnldButtonMsg = 'Download precedence summary:arrow_down:'\n",
        "    vGenericDwnldButtonMsg = 'Download :arrow_down:'\n",
        "    vSmryFileNm='summary'\n",
        "    vArbRespFileNm='arbitration'\n",
        "    vPrcedncRespFileNm='precedence'\n",
        "    vIsArbitrationQue = 'Step 2. Would you like to check if this case qualifies for private arbitration?'\n",
        "    vOptionNo='No'\n",
        "    vOptionYes='Yes'\n",
        "    vIsPrecedenceQue='Step 3. Would you like to check for precedence?'\n",
        "    vCaseSummaryQue='Step 1. Please upload the case file to begin'\n",
        "    vDisclaimerArb='Views expressed by the system are generated by an artificial intelligence. It is important to consult with a qualified attorney to further evaluate the \\\n",
        "      specific circumstances of the case and ensure compliance with the latest legal structure in Brazil.'\n",
        "    vDisclaimerPrec='As an A.I, I have limited access to prior legal files. We are working in the background to bring this feature soon.'\n",
        "  else:\n",
        "    vPgHome = 'lar'\n",
        "    vPgSetting = 'contexto'\n",
        "    vHomeTitle = '**Bem-vindo ao seu prÃ³prio assistente jurÃ­dico de A.I**'\n",
        "    vHomeHeader = 'Por toda a sua assistÃªncia jurÃ­dica, como resumir arquivos de casos, identificar o judiciÃ¡rio correto a ser instaurado e muito mais. \\\n",
        "      \\n\\\n",
        "      Muitos mais recursos estÃ£o chegando. Fique atento!'\n",
        "    vSettingPgHeader='trabalho em progresso...'\n",
        "    vFileUpldrLabel='Carregar arquivo do caso'\n",
        "    vSubmitHomeFileUpldLabel=\"Resumir\"\n",
        "    vCheckButtonLabel=\"Enviar\"\n",
        "    css='''\n",
        "      <style>\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::before {content:\"Arraste e solte o arquivo aqui\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div span{display:none;}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div::after {color:grey; font-size: .8em; content:\"Limite de 20MB por arquivo â€¢ PDF\"}\n",
        "      [data-testid=\"stFileUploadDropzone\"] div div small{display:none;}\n",
        "      </style>\n",
        "      '''\n",
        "    st.markdown(css, unsafe_allow_html=True)\n",
        "    vResponseTitle='Resumindo '\n",
        "    vWarningNoFileUpld = 'Aviso: faÃ§a upload do arquivo do caso para prosseguir'\n",
        "    vSmryDwnldButtonMsg = 'Baixar resumo do caso :arrow_down:'\n",
        "    vArbDwnldButtonMsg = 'Baixe o resumo da arbitragem :arrow_down:'\n",
        "    vPrecDwnldButtonMsg = 'Baixar resumo de precedÃªncia :arrow_down:'\n",
        "    vGenericDwnldButtonMsg = 'Baixar :arrow_down:'\n",
        "    vSmryFileNm='resumido'\n",
        "    vArbRespFileNm='arbitragem'\n",
        "    vPrcedncRespFileNm='precedÃªncia'\n",
        "    vIsArbitrationQue = 'Etapa 2. Gostaria de verificar se este caso se qualifica para arbitragem privada?'\n",
        "    vOptionNo='NÃ£o'\n",
        "    vOptionYes='Sim'\n",
        "    vIsPrecedenceQue='Etapa 3. Gostaria de verificar a precedÃªncia?'\n",
        "    vDisclaimerArb='As opiniÃµes expressas pelo sistema sÃ£o geradas por uma inteligÃªncia artificial. Ã‰ importante consultar um advogado qualificado para avaliar melhor o \\\n",
        "      circunstÃ¢ncias especÃ­ficas do caso e garantir o cumprimento da mais recente estrutura jurÃ­dica do Brasil.'\n",
        "    vDisclaimerPrec='Como A.I, tenho acesso limitado a arquivos jurÃ­dicos antigos. Mas estamos trabalhando em segundo plano para trazer esse recurso em breve.'\n",
        "    vCaseSummaryQue='Etapa 1. FaÃ§a upload do arquivo do caso para comeÃ§ar'\n",
        "\n",
        "  load_dotenv()\n",
        "  openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "  input_files = []\n",
        "  vUpldMultipleFiles = False\n",
        "  vResponse = \"\"\n",
        "  flName = \"\"\n",
        "  vPg = vPgHome\n",
        "  # llm_model = \"gpt-3.5-turbo\" #For Dev\n",
        "  llm_model = \"gpt-4\" #For Prod\n",
        "\n",
        "  ### Initiate logging ###\n",
        "  logger_format = (\n",
        "      \"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \"\n",
        "      \"<level>{level: <8}</level> | \"\n",
        "      \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | \"\n",
        "      +username+\" | \"\n",
        "      \"{extra[ip]} {extra[user]} - <level>{message}</level>\"\n",
        "  )\n",
        "  logger.configure(extra={\"ip\": \"\", \"user\": \"\"})  # Default values\n",
        "  logger.remove()\n",
        "  logger.add(username+\"_{time:YYYY-MM-DD!UTC}.log\", format=logger_format, rotation=\"10 MB\", compression=\"zip\")\n",
        "  logger.info(\"*********** Started Assistente ***********\")\n",
        "\n",
        "  ### Start funcs definitions ###\n",
        "\n",
        "  encoding = tiktoken.encoding_for_model(llm_model)\n",
        "  def num_tokens_from_response(response_text):\n",
        "    num_tokens = len(encoding.encode(response_text))\n",
        "    return num_tokens\n",
        "\n",
        "  def num_tokens_from_messages(messages):\n",
        "    tokens_per_message = 3\n",
        "    tokens_per_name = 1\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "      num_tokens += tokens_per_message\n",
        "      for key, value in message.items():\n",
        "        num_tokens += len(encoding.encode(value))\n",
        "        if key == \"name\":\n",
        "          num_tokens += tokens_per_name\n",
        "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
        "    return num_tokens\n",
        "\n",
        "  def getOpenaiApiCost(llm_name,completion_tokens,prompt_tokens):\n",
        "    if llm_name == \"gpt-3.5-turbo\":\n",
        "      ###\t4K context: Input/Prompt tokens @ $0.0015/1K tokens, Output/Response tokens @ $0.002/1K tokens\n",
        "      ip_cost = (prompt_tokens/1000) * 0.0015\n",
        "      op_cost = (completion_tokens/1000) * 0.002\n",
        "\n",
        "    elif llm_name == \"gpt-3.5-turbo-16k\":\n",
        "      ###\t16K context: Input/Prompt tokens @ $0.003/1K tokens, Output/Response tokens @ $0.004/1K tokens\n",
        "      ip_cost = (prompt_tokens/1000) * 0.003\n",
        "      op_cost = (completion_tokens/1000) * 0.004\n",
        "\n",
        "    elif llm_name == \"gpt-4\":\n",
        "      ###\t8K context: Input/Prompt tokens @ $0.03/1K tokens, Output/Response tokens @ $0.06/1K tokens\n",
        "      ip_cost = (prompt_tokens/1000) * 0.03\n",
        "      op_cost = (completion_tokens/1000) * 0.06\n",
        "\n",
        "    tot_cost = round((op_cost + ip_cost),4)\n",
        "    return (tot_cost)\n",
        "\n",
        "  def getFileData(rawFileData):\n",
        "    file_extension = pathlib.Path(rawFileData.name).suffix\n",
        "    logger.info(\"file_extension:{var}\",var=file_extension)\n",
        "    if file_extension.upper()=='.TXT':\n",
        "      file_data = rawFileData.getvalue().decode('utf-8')\n",
        "    elif file_extension.upper()=='.PDF':\n",
        "      file_pages = []\n",
        "      p = io.BytesIO(rawFileData.getvalue());\n",
        "      pdf = PyPDF2.PdfReader(p)\n",
        "      for page in pdf.pages:\n",
        "        text = page.extract_text()\n",
        "        file_pages.append(text)\n",
        "        file_data = ''\n",
        "        for k in range(len(file_pages)):\n",
        "          file_data = file_data + file_pages[k]\n",
        "    logger.info(\"Data from file:{var}\",var=file_data)\n",
        "    return file_data\n",
        "\n",
        "  def getAiMessages(prompt):\n",
        "     message = [{\"role\": \"system\", \"content\": \"Assistant is an highly experienced lawyer from Brazil,\\\n",
        "     who knows both portugese and english language and is an expert in all matters related to legal, judicial,\\\n",
        "     and laws\"},{\"role\": \"user\", \"content\": prompt}]\n",
        "     return message\n",
        "\n",
        "  def getAiResponse(message, isStreaming, prompt, llm_model, temperature):\n",
        "    result = \"\"\n",
        "    collected_messages = []\n",
        "    report1 = []\n",
        "    res_box1 = st.empty()\n",
        "    response = openai.ChatCompletion.create(model=llm_model, messages=message, temperature=temperature, stream=isStreaming,)\n",
        "    for chunk in response:\n",
        "      chunk_message = chunk['choices'][0]['delta']\n",
        "      collected_messages.append(chunk_message)\n",
        "      if \"content\" in chunk_message:\n",
        "        report1.append(chunk_message['content'])\n",
        "        result = \"\".join(report1)\n",
        "        res_box1.success(f'*{result}*')\n",
        "    vResponse = [''.join([m.get('content', '') for m in collected_messages])]\n",
        "    return vResponse\n",
        "\n",
        "  def getSmryPrompt(data):\n",
        "    if (st.session_state[\"vLang\"]):\n",
        "      vLang = 'English'\n",
        "    else:\n",
        "      vLang = 'Portueguese'\n",
        "    prompt = f\"\"\"Your task is to summarize in atleast 300 words, the legal document provided between three backticks in {vLang} language.\n",
        "    It is VERY IMPORTANT that you include only the summarised text and nothing else, not a title, post script or any other text.\n",
        "    You will summarise the legal document in the format and language of a very efficient and experienced advocate.\n",
        "\n",
        "    It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    After fetching the response, you will review the response to check if you have followed the critera provided between\\\n",
        "     triple commas as delimiters\n",
        "    ,,,You will review the summary for any important legal points which is missed.\n",
        "    You should review as per the latest legal structure of Brazil.\n",
        "    You will include all personal information or PII data related to any person, all dates, names of places, companies etc.\n",
        "    Include only the summarized response. Do not include any title or post script or anyother text which is not related \\\n",
        "    to the legal document provided between three backticks\\\n",
        "    The response should be in {vLang} language.\n",
        "    ,,,\n",
        "    ```{data}```\n",
        "    \"\"\"\n",
        "\n",
        "    # prompt = f\"\"\"Your task is to summarize in less than 10 words, the legal document provided between three backticks in {vLang} language.\n",
        "    # It is VERY IMPORTANT that you include only the summarised text and nothing else, not a title, post script or any other text.\n",
        "    # You will summarise the legal document in the format and language of a very efficient and experienced advocate.\n",
        "\n",
        "    # It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    # After fetching the response, you will review the response to check if you have followed the critera provided between\\\n",
        "    #  triple commas as delimiters\n",
        "    # ,,,You will review the summary for any important legal points which is missed.\n",
        "    # You should review as per the latest legal structure of Brazil.\n",
        "    # You will include all personal information or PII data related to any person, all dates, names of places, companies etc.\n",
        "    # Include only the summarized response. Do not include any title or post script or anyother text which is not related \\\n",
        "    # to the legal document provided between three backticks\\\n",
        "    # The response should be in {vLang} language.\n",
        "    # ,,,\n",
        "    # ```{data}```\n",
        "    # \"\"\"\n",
        "    logger.info(prompt)\n",
        "    return prompt\n",
        "\n",
        "  def getPromptIsArbitration(data):\n",
        "    if (st.session_state[\"vLang\"]):\n",
        "      vLang = 'English'\n",
        "    else:\n",
        "      vLang = 'Portuguese'\n",
        "\n",
        "    prompt = f\"\"\"Your task is to check if the case summary provided between three backticks, \\\n",
        "    qualify for private arbitrage in brazil.\\\n",
        "    You will arrive at the decision by considering the Brazil Arbitration Act (Law No. 9.307/1996).\n",
        "    It is VERY IMPORTANT that you consider the guidelines provided between three tilde symbols.\n",
        "    ~~~\n",
        "    You will assume that both parties have consented for entering into an written arbitration agreement.\n",
        "    Carefully analyze the case summary provided the between three backticks to see if this case qualifies to be tried under \\\n",
        "    private arbitration in Brazil under Brazil Arbitration Act (Law No. 9.307/1996)?\n",
        "    You will use the tone and language of an experienced advocate from Brazil.\n",
        "    You will not paraphrase or include the case summary in your response.\n",
        "    The decision should be based only on Brazil Arbitration Act (Law No. 9.307/1996).~~~\n",
        "\n",
        "    It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    After fetching the response, you will STRICTLY ensure the response follows the guidelines mentioned between three plus signs.\\\n",
        "    +++Your response should only the clarification whether the case qualifies for private arbitration in Brazil. \\\n",
        "    It should also have the why or the reason for considering this under private arbitration.\n",
        "    You should remove the intial paraphrasing of summary from the response.\n",
        "    The language of response should be in {vLang}.\n",
        "    +++\n",
        "\n",
        "    ```{data}```\n",
        "    \"\"\"\n",
        "\n",
        "    # prompt = f\"\"\"Your task is to check if the case summary provided between three backticks, \\\n",
        "    # qualify for private arbitrage in brazil.\\\n",
        "    # You will arrive at the decision by considering the Brazil Arbitration Act (Law No. 9.307/1996).\n",
        "    # It is VERY IMPORTANT that you consider the guidelines provided between three tilde symbols.\n",
        "    # ~~~\n",
        "    # You will assume that both parties have consented for entering into an written arbitration agreement.\n",
        "    # Carefully analyze the case summary provided the between three backticks to see if this case qualifies to be tried under \\\n",
        "    # private arbitration in Brazil under Brazil Arbitration Act (Law No. 9.307/1996)?\n",
        "    # You will use the tone and language of an experienced advocate from Brazil.\n",
        "    # You will not paraphrase or include the case summary in your response.\n",
        "    # The decision should be based only on Brazil Arbitration Act (Law No. 9.307/1996).~~~\n",
        "\n",
        "    # It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language in LESS THAN 10 WORDS.\n",
        "\n",
        "    # After fetching the response, you will STRICTLY ensure the response follows the guidelines mentioned between three plus signs.\\\n",
        "    # +++Your response should only the clarification whether the case qualifies for private arbitration in Brazil. \\\n",
        "    # It should also have the why or the reason for considering this under private arbitration.\n",
        "    # You should remove the intial paraphrasing of summary from the response.\n",
        "    # The language of response should be in {vLang}.\n",
        "    # +++\n",
        "\n",
        "    # ```{data}```\n",
        "    # \"\"\"\n",
        "\n",
        "    logger.info(prompt)\n",
        "    return prompt\n",
        "\n",
        "  def getPromptIsPrecedence(data, vDisclaimerPrec):\n",
        "    if (st.session_state[\"vLang\"]):\n",
        "      vLang = 'English'\n",
        "    else:\n",
        "      vLang = 'Portuguese'\n",
        "\n",
        "    prompt = f\"\"\"Your task is to check if the case summary provided between three backticks, \\\n",
        "    has any precedence in in brazil. You will arrive at the decision by following the instructions given between three Tilde symbols.\n",
        "    ~~~ Carefully analyze the case summary provided the between three backticks.\n",
        "    Compare it against the cases from Brazil legal system, to only what you have access to.\n",
        "    If you do not have any access, do not generate hallucinations or imaginary cases.\n",
        "    Check the precedence of the similar case in this 10 years of Brazil's legal system.~~~\n",
        "\n",
        "    It is VERY IMPORTANT that you STRICTLY provide response in {vLang} language.\n",
        "\n",
        "    After fetching the response, you will STRICTLY follow the guidelines given between three Hash symbols.\\\n",
        "    ### You will rewrite the response in the tone, format and language of a very efficient and highly experienced advocate from Brazil.\\\n",
        "    You will check TWICE whether the precedence cited are imaginary or hallucinations. If they are either, you will reject them.\n",
        "    You will check TWICE whether the Citation URLs are working or not. If they are not working, you will not include any imaginary or placeholder URLs.\n",
        "    You will not include any summary of the case provided between three backticks. You will only include details of the precedence\n",
        "\n",
        "    You will give your response in only STRICTLY IN JSON format and in {vLang} language. You will not provide any other text beyond this JSON data in {vLang} language.\n",
        "    [Case_file=input details of precedence cases,Verdict_Date=Input date of precedence cases here, Judgement=Input the verdict give and against whom in the preceednce case, Citation=Input the working URL to the precedence case]\n",
        "    ,[Case_file=input details of precedence cases,Verdict_Date=Input date of precedence cases here, Judgement=Input the verdict give and against whom in the preceednce case, Citation=Input the working URL to the precedence case]\n",
        "    If you do not have any precedence case, you will respond with empty JSON.\n",
        "\n",
        "    Before generating the response you will again check whether the response follows the guidelines given between three Hash symbols.\n",
        "\n",
        "    You will give your response in only STRICTLY IN JSON format. You will not provide any other text beyond this JSON data.\n",
        "    If you do not have any precedence case, you will respond with JSON in below format.\n",
        "    [{vDisclaimerPrec}]\n",
        "\n",
        "    ```{data}```\n",
        "    \"\"\"\n",
        "\n",
        "    logger.info(prompt)\n",
        "    return prompt\n",
        "\n",
        "  def renderHomePgHeader():\n",
        "    st.subheader(vHomeTitle)\n",
        "    st.info(vHomeHeader)\n",
        "\n",
        "  def renderSettingPg():\n",
        "    st.subheader(vSettingPgHeader)\n",
        "\n",
        "  # @logger.catch\n",
        "  # @st.cache_data(max_entries=3,ttl=3600,show_spinner=False)\n",
        "  # def summarizeFiles(data):\n",
        "  #   prompt = getSmryPrompt(data)\n",
        "  #   vResponse = getAiResponse(True,prompt,llm_model,0.3)\n",
        "  #   return vResponse[0]\n",
        "\n",
        "  def renderResponse(df):\n",
        "    st.divider()\n",
        "    st.dataframe(df, use_container_width=True)\n",
        "    st.divider()\n",
        "\n",
        "  def renderMenubar():\n",
        "    col1, col2 = st.columns([0.5, 0.5])\n",
        "    with col1:\n",
        "      vPg = option_menu(None, [vPgHome, vPgSetting],\n",
        "      icons=['house', 'gear'],\n",
        "      menu_icon=\"cast\", default_index=0, orientation=\"horizontal\")\n",
        "    with col2:\n",
        "      st.write(' ')\n",
        "    return vPg\n",
        "\n",
        "  def dwnldSmryResp(data):\n",
        "    return data\n",
        "\n",
        "  def dwnldArbResp(data):\n",
        "    return data\n",
        "\n",
        "  def dwnldPrcedncResp(data):\n",
        "    if str(data[0]) == '{}':\n",
        "      return vDisclaimerPrec\n",
        "    else:\n",
        "      return data\n",
        "\n",
        "################################################################################\n",
        "\n",
        "  # vPg = renderMenubar()\n",
        "  if vPg == vPgHome:\n",
        "    renderHomePgHeader()\n",
        "    col1, col2, col3 = st.columns([0.15,0.7,0.15])\n",
        "    with col1:\n",
        "      st.write(\" \")\n",
        "    with col2:\n",
        "      tab1, tab2 = st.tabs([\" \",\" \"])\n",
        "      with tab1:\n",
        "        with st.form(\"smry\", clear_on_submit=True):\n",
        "          col4, col5 = st.columns([0.85,0.15])\n",
        "          with col4:\n",
        "            st.subheader(vCaseSummaryQue)\n",
        "          with col5:\n",
        "            vSubmitHomeFileUpld = st.form_submit_button(vSubmitHomeFileUpldLabel, type=\"primary\")\n",
        "          input_files = st.file_uploader(\"\", type=['pdf'], accept_multiple_files=vUpldMultipleFiles,key=st.session_state[\"file_uploader_key\"],label_visibility=\"visible\")\n",
        "          if vSubmitHomeFileUpld and not(input_files):\n",
        "            st.warning(vWarningNoFileUpld)\n",
        "            st.session_state[\"vSmry\"] = \"\"\n",
        "          if vSubmitHomeFileUpld and not(not(input_files)):\n",
        "            fl_ext = pathlib.Path(input_files.name).suffix\n",
        "            st.session_state[\"vflNm\"] = input_files.name.replace(fl_ext,'')\n",
        "\n",
        "            with st.spinner('Processing...'):\n",
        "              file_data = getFileData(input_files).strip()\n",
        "              st.session_state[\"vFileData\"]=file_data\n",
        "              prompt = getSmryPrompt(file_data)\n",
        "              message = getAiMessages(prompt)\n",
        "              prompt_tokens = num_tokens_from_messages(message)\n",
        "\n",
        "            tokenSzExceed = False\n",
        "            if prompt_tokens < 4000:\n",
        "              smry_llm=\"gpt-3.5-turbo\"\n",
        "            elif prompt_tokens > 4000 and prompt_tokens < 8000:\n",
        "              smry_llm=\"gpt-4\"\n",
        "            elif prompt_tokens > 8000 and prompt_tokens < 16000:\n",
        "              smry_llm=\"gpt-3.5-turbo-16k\"\n",
        "            else:\n",
        "              tokenSzExceed = True\n",
        "\n",
        "            if not(tokenSzExceed):\n",
        "              vResponse = getAiResponse(message, True, prompt, smry_llm, 0)\n",
        "              st.session_state[\"vSmry\"] = vResponse[0]\n",
        "              completion_tokens = num_tokens_from_response(st.session_state[\"vSmry\"])\n",
        "            else:\n",
        "              st.error(\"prompt_tokens:\"+str(prompt_tokens))\n",
        "              st.error('Currently system can handle only small case files.\\\n",
        "                \\n\\\n",
        "                We are working in the background to increase this limit!')\n",
        "\n",
        "        col1,col2 = st.columns([0.7,0.3])\n",
        "        with col1:\n",
        "          st.write('')\n",
        "        with col2:\n",
        "          if st.session_state[\"vSmry\"] != '':\n",
        "            st.write()\n",
        "            st.download_button(vSmryDwnldButtonMsg, (st.session_state[\"vSmry\"]), file_name=st.session_state[\"vflNm\"]+'_'+vSmryFileNm+'.txt', type=\"secondary\", key='SmryDwnld', use_container_width=True)\n",
        "\n",
        "        if st.session_state[\"vSmry\"] != '':\n",
        "          st.write(\"--------------------------------------------------------------\")\n",
        "          with st.form(\"arbitr\", clear_on_submit=True):\n",
        "            col1,col2 = st.columns([0.85,0.15])\n",
        "            with col1:\n",
        "              st.write(vIsArbitrationQue)\n",
        "            with col2:\n",
        "              vIsArbitrationSubmit = st.form_submit_button(vCheckButtonLabel, type=\"primary\")\n",
        "            if vIsArbitrationSubmit:\n",
        "              st.session_state[\"vIsArbSubmit\"] = True\n",
        "              with st.expander('', expanded=True):\n",
        "                prompt = getPromptIsArbitration(st.session_state[\"vSmry\"])\n",
        "                message = getAiMessages(prompt)\n",
        "                vResp = getAiResponse(message,True,prompt,llm_model,0)\n",
        "                st.session_state[\"vArbResp\"] = vResp[0]\n",
        "\n",
        "        if st.session_state[\"vArbResp\"]:\n",
        "          col1,col2 = st.columns([0.65,0.35])\n",
        "          with col1:\n",
        "            st.write('')\n",
        "          with col2:\n",
        "            st.download_button(vArbDwnldButtonMsg, dwnldArbResp(st.session_state[\"vArbResp\"]), file_name=st.session_state[\"vflNm\"]+'_'+vArbRespFileNm+vSmryFileNm+'.txt', type=\"secondary\", key='IsArbitrationDwnld',use_container_width=True)\n",
        "          st.caption(f':Gray[{vDisclaimerArb}]')\n",
        "          st.session_state[\"vIsArbSubmit\"] = False\n",
        "\n",
        "        if st.session_state[\"vFileData\"] != '':\n",
        "          st.write(\"--------------------------------------------------------------\")\n",
        "          with st.form(\"prece\", clear_on_submit=True):\n",
        "            col1,col2 = st.columns([0.85,0.15])\n",
        "            with col1:\n",
        "              st.write(vIsPrecedenceQue)\n",
        "            with col2:\n",
        "              vIsPrecedenceSubmit = st.form_submit_button(vCheckButtonLabel, type=\"primary\")\n",
        "            if vIsPrecedenceSubmit and st.session_state[\"vFileData\"] != '':\n",
        "              with st.expander('', expanded=True):\n",
        "                prompt = getPromptIsPrecedence(st.session_state[\"vSmry\"], vDisclaimerPrec)\n",
        "                message = getAiMessages(prompt)\n",
        "                # vResp = getAiResponse(message,True,prompt,llm_model,0)\n",
        "                # st.session_state[\"vPrcedncResp\"] = vResp[0]\n",
        "                st.session_state[\"vPrcedncResp\"] = vDisclaimerPrec\n",
        "                st.success(vDisclaimerPrec)\n",
        "\n",
        "        if st.session_state[\"vPrcedncResp\"] != '':\n",
        "          col1,col2 = st.columns([0.64,0.36])\n",
        "          with col1:\n",
        "            st.write('')\n",
        "          with col2:\n",
        "            st.download_button(vPrecDwnldButtonMsg, dwnldPrcedncResp(st.session_state[\"vPrcedncResp\"]), file_name=st.session_state[\"vflNm\"]+'_'+vPrcedncRespFileNm+vSmryFileNm+'.txt', type=\"secondary\", key='IsPrcedncDwnld',use_container_width=True)\n",
        "          # st.caption(f':Gray[{vDisclaimerPrec}]')\n",
        "      with tab2:\n",
        "        st.write('')\n",
        "\n",
        "    with col3:\n",
        "      st.write(\" \")\n",
        "\n",
        "elif st.session_state[\"authentication_status\"] is False:\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    st.write('')\n",
        "  with col2:\n",
        "    st.error('Username/password is incorrect')\n",
        "  with col3:\n",
        "    st.write('')\n",
        "elif st.session_state[\"authentication_status\"] is None:\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    st.write('')\n",
        "  with col2:\n",
        "    st.warning('Please enter your username and password')\n",
        "  with col3:\n",
        "    st.write('')\n",
        "else:\n",
        "  col1, col2, col3 = st.columns(3)\n",
        "  with col1:\n",
        "    st.write('')\n",
        "  with col2:\n",
        "    st.error('Contact admin @ maneshgpai@gmail.com')\n",
        "  with col3:\n",
        "    st.write('')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq7VLkrECcWE"
      },
      "source": [
        "#Code to generate unique pass key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKGiW6EZCbqw"
      },
      "outputs": [],
      "source": [
        "# pip install cryptography\n",
        "from cryptography.fernet import Fernet\n",
        "# Put this somewhere safe!\n",
        "key = Fernet.generate_key()\n",
        "print(key)\n",
        "f = Fernet(key)\n",
        "token = f.encrypt(b\"medcodecookie\")\n",
        "print(token)\n",
        "\n",
        "### To decrypt the key:\n",
        "# f.decrypt(token)\n",
        "\n",
        "### Keys generated for stauth YAML:\n",
        "# Crypto fernet key: Rf7N6vpG_G_2MITkoJ9KbN4HRfNoWpyBdrYwIiU_9vc=\n",
        "# Cookie key for stauth YAML file: gAAAAABlJVNLvN6Yi0KH-xmBGP3lJYw7YDWdPr-dHn4hC0IR2foOai1GGTszI7MCcijAyecLKrk3GiJp_dTaQ47bsBqRN1k-vA==\n",
        "# Cookie Name for stauth YAML file: medcodecookie"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM69bceEp4FQe9ibsnt6aav",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}